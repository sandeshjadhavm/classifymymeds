{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c2a9f4-eb3e-4fa7-819d-55e40e11c3e0",
   "metadata": {},
   "source": [
    "# Prior Authorization Classifier\n",
    "\n",
    "In this notebook, we survey various classifiers on different sets of features predicting whether a prior authorization, or PA, will get approved. According to our evaluations and comparison with the baseline model always predicting 1, we conclude that roc auc score is most suitable for selecting models. We see that a good choice of models for highest roc auc score are decision tree and random forest. With an analysis in [feature importances](./pa_classifier_feature_importances.ipynb), we decide that random forest is the best one. In the end, we add an appendix arguing why accuracy is not a good measure of models in this prior authorization classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25863971-1df9-4f1f-bda6-505bc5c41f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "import seaborn as sns\n",
    "import dataframe_image as dfi\n",
    "import upsetplot\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# import utils for loading data\n",
    "# see `load_tables` in utils.py\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f4b2df-df99-4837-8d28-72235ea6ccc0",
   "metadata": {},
   "source": [
    "## Load PA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ab4cec-2974-4adc-a10f-0451fb3bd84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_claim_id</th>\n",
       "      <th>bin</th>\n",
       "      <th>drug</th>\n",
       "      <th>reject_code</th>\n",
       "      <th>pharmacy_claim_approved</th>\n",
       "      <th>dim_pa_id</th>\n",
       "      <th>dim_date_id</th>\n",
       "      <th>correct_diagnosis</th>\n",
       "      <th>tried_and_failed</th>\n",
       "      <th>contraindication</th>\n",
       "      <th>pa_approved</th>\n",
       "      <th>date_val</th>\n",
       "      <th>calendar_year</th>\n",
       "      <th>calendar_month</th>\n",
       "      <th>calendar_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekday</th>\n",
       "      <th>is_workday</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>417380</td>\n",
       "      <td>A</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>417740</td>\n",
       "      <td>A</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>417380</td>\n",
       "      <td>A</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>999001</td>\n",
       "      <td>A</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>417614</td>\n",
       "      <td>A</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dim_claim_id     bin drug  reject_code  pharmacy_claim_approved  \\\n",
       "0              1  417380    A           75                        0   \n",
       "2              3  417740    A           76                        0   \n",
       "9             10  417380    A           75                        0   \n",
       "10            11  999001    A           76                        0   \n",
       "14            15  417614    A           70                        0   \n",
       "\n",
       "    dim_pa_id  dim_date_id  correct_diagnosis  tried_and_failed  \\\n",
       "0         1.0            1                  1                 1   \n",
       "2         2.0            1                  1                 0   \n",
       "9         3.0            1                  0                 0   \n",
       "10        4.0            1                  1                 1   \n",
       "14        5.0            1                  0                 1   \n",
       "\n",
       "    contraindication  pa_approved    date_val  calendar_year  calendar_month  \\\n",
       "0                  0            1  2017-01-01           2017               1   \n",
       "2                  0            1  2017-01-01           2017               1   \n",
       "9                  1            1  2017-01-01           2017               1   \n",
       "10                 0            1  2017-01-01           2017               1   \n",
       "14                 0            1  2017-01-01           2017               1   \n",
       "\n",
       "    calendar_day  day_of_week  is_weekday  is_workday  is_holiday  \n",
       "0              1            1           0           0           1  \n",
       "2              1            1           0           0           1  \n",
       "9              1            1           0           0           1  \n",
       "10             1            1           0           0           1  \n",
       "14             1            1           0           0           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = utils.load_tables()['dim_pa_full']\n",
    "df_pa.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436a8c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 555951 entries, 0 to 1335573\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   dim_claim_id             555951 non-null  int64  \n",
      " 1   bin                      555951 non-null  object \n",
      " 2   drug                     555951 non-null  object \n",
      " 3   reject_code              555951 non-null  int32  \n",
      " 4   pharmacy_claim_approved  555951 non-null  int64  \n",
      " 5   dim_pa_id                555951 non-null  float64\n",
      " 6   dim_date_id              555951 non-null  int64  \n",
      " 7   correct_diagnosis        555951 non-null  int32  \n",
      " 8   tried_and_failed         555951 non-null  int32  \n",
      " 9   contraindication         555951 non-null  int32  \n",
      " 10  pa_approved              555951 non-null  int32  \n",
      " 11  date_val                 555951 non-null  object \n",
      " 12  calendar_year            555951 non-null  int64  \n",
      " 13  calendar_month           555951 non-null  int64  \n",
      " 14  calendar_day             555951 non-null  int64  \n",
      " 15  day_of_week              555951 non-null  int64  \n",
      " 16  is_weekday               555951 non-null  int64  \n",
      " 17  is_workday               555951 non-null  int64  \n",
      " 18  is_holiday               555951 non-null  int64  \n",
      "dtypes: float64(1), int32(5), int64(10), object(3)\n",
      "memory usage: 74.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_pa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77cd47fd-10a6-4944-87a9-b14f51b40085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "\n",
    "df_copy = df_pa.copy()\n",
    "\n",
    "# a random feature is added for comparison of feature importances\n",
    "df_copy['random'] = np.random.rand(df_copy.shape[0])\n",
    "\n",
    "df_train_val = df_copy.sample(\n",
    "    frac=0.8,\n",
    "    random_state=614 # optional: use random_state for reproducibility\n",
    ")\n",
    "\n",
    "# test data\n",
    "df_test = df_copy.drop(df_train_val.index)\n",
    "\n",
    "# train data\n",
    "df_train = df_train_val.sample(\n",
    "    frac=0.9,\n",
    "    random_state=614\n",
    ")\n",
    "\n",
    "# validation data\n",
    "df_val = df_train_val.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c82ae-1f71-4654-8c9b-334abdb6b5e6",
   "metadata": {},
   "source": [
    "## Model Evaluations\n",
    "\n",
    "The features we have for PA classification are `bin`, `drug`, `reject_code`, `correct_diagnosis`, `tried_and_failed` and `contraindication`. From our data exploration, `reject_code` for a fixed pair of (`bin`, `drug`) is also fixed. So we leave `reject_code` out in this section. We fit **Logistic Regression**, **Linear SVC**, **Decision Tree Classifier**, **Random Forest Classifier**, **Voting Classifier** and **AdaBoost Classifier** on all possible non-empty feature subsets. Note that we added a random feature to serve as a pivot. After fitting the model on the training data, we compute various scores of the model on the training, testing and validation data. \n",
    "\n",
    "After the evaluation, we can use the result to determine the best feature sets for models. We can also use it to compute the drop-feature importances, see [this notebook](./pa_classifier_feature_importances.ipynb) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c52d162c-4765-4659-abd2-204dc043ba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 features:\n",
      "['bin', 'drug', 'correct_diagnosis', 'tried_and_failed', 'contraindication', 'random']\n",
      "\n",
      "Models to fit and evaluate: \n",
      "['Decision Tree', 'Random Forest']\n",
      "\n",
      "Scores to evaluate models: \n",
      "['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "# import models that we are going to fit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import scores to evaluate models\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# numerical columns of the dataframe (df_train and etc.) to use\n",
    "# note that we added a column of random noise\n",
    "num_cols = ['correct_diagnosis', 'tried_and_failed', 'contraindication', 'random']\n",
    "# categorical columns of the dataframe to use\n",
    "cat_cols = ['bin', 'drug']\n",
    "# all feature columns\n",
    "all_cols = cat_cols + num_cols\n",
    "\n",
    "# set up the list of models to fit and evaluate\n",
    "models = [\n",
    "    ('Decision Tree', DecisionTreeClassifier()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "]\n",
    "\n",
    "\n",
    "# set up the list of scores to evaluate models\n",
    "score_funcs = [\n",
    "    ('accuracy', accuracy_score),\n",
    "    ('precision', precision_score),\n",
    "    ('recall', recall_score),\n",
    "    ('f1', f1_score),\n",
    "    ('roc_auc', roc_auc_score),\n",
    "]\n",
    "\n",
    "# print out some info\n",
    "print(f'There are {len(all_cols)} features:\\n{all_cols}')\n",
    "print()\n",
    "print(f'Models to fit and evaluate: \\n{[n for n, _ in models]}')\n",
    "print()\n",
    "print(f'Scores to evaluate models: \\n{[s for s, _ in score_funcs]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaa6df9-5283-44a4-9de0-da5212d7d764",
   "metadata": {},
   "source": [
    "Since we have 6 features, so we have a total of 63 non-empty feature subsets. We can number these subsets from 1 to 63."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5207b984-9153-4d41-936c-86e35deda649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(fid):\n",
    "    '''Get the feature subset from the fid between 1 and 63.\n",
    "    '''\n",
    "    fin_bin = [(fid >> i) & 1 for i in range(len(all_cols))]\n",
    "    feats = [f for b, f in zip(fin_bin, all_cols) if b]\n",
    "    num_feats = [f for f in feats if f in num_cols]\n",
    "    cat_feats = [f for f in feats if f in cat_cols]\n",
    "    return num_feats, cat_feats, feats\n",
    "\n",
    "def save_evaluate_data(data, path=None):\n",
    "    '''Save evaluation data to a csv file.\n",
    "    \n",
    "    The csv file will have 5 columns:\n",
    "        - fid: a number to identify the feature subset\n",
    "        - model: name of the model in evaluation\n",
    "        - data_type: one of {'train', 'test', 'validation'} indicating which\n",
    "            dataset is used to evaluate the model\n",
    "        - score_func: name of the scoring function\n",
    "        - score: acutal score of the evaluation\n",
    "    \n",
    "    Args:\n",
    "        data (list): each element is a list of 5 items, one for each column\n",
    "        path (str, optional): path to save the csv file\n",
    "    '''\n",
    "    df_models = pd.DataFrame(\n",
    "        data=data,\n",
    "        columns=['fid', 'model', 'data_type', 'score_func', 'score']\n",
    "    )\n",
    "    if path:\n",
    "        df_models.to_csv(path, index=False)\n",
    "    return df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5cb825e-7834-40cb-b264-56ae844f8f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fid</th>\n",
       "      <th>bin</th>\n",
       "      <th>drug</th>\n",
       "      <th>correct_diagnosis</th>\n",
       "      <th>tried_and_failed</th>\n",
       "      <th>contraindication</th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fid  bin  drug  correct_diagnosis  tried_and_failed  contraindication  \\\n",
       "0    0    0     0                  0                 0                 0   \n",
       "1    1    1     0                  0                 0                 0   \n",
       "2    2    0     1                  0                 0                 0   \n",
       "3    3    1     1                  0                 0                 0   \n",
       "4    4    0     0                  1                 0                 0   \n",
       "\n",
       "   random  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsets = []\n",
    "for fid in range(2 ** len(all_cols)):\n",
    "    fid_bin = [(fid >> i) & 1 for i in range(len(all_cols))]\n",
    "    subsets.append(fid_bin)\n",
    "\n",
    "df_features = pd.DataFrame(\n",
    "    data=subsets, columns=all_cols\n",
    ").reset_index().rename(columns={'index': 'fid'})\n",
    "\n",
    "df_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ad226b8-5ce3-450f-ba8b-c3f31f14cc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bin', 'drug']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features(3)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e4d72d-7630-4fc9-b0a4-e4fbf1c615d9",
   "metadata": {},
   "source": [
    "The dataframe `df_features` lists all subset of features with index being their `fid`s, compatible with `get_features`. For example, `get_features(3)[2] = ['bin', 'drug']` and `df_features` has `bin` and `drug` set to 1 at when `fid = 3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d018b02-ecca-4c01-aced-912efa812c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the return of evaluate_model will be elements in the data argument\n",
    "# in the save_evaluation_data function above\n",
    "def evaluate_model(fid, model, name, X, y, data_type, score_name, score_func):\n",
    "    y_pred = model.predict(X)\n",
    "    score = score_func(y, y_pred)\n",
    "    return (fid, name, data_type, score_name, score)\n",
    "\n",
    "# get the target variables\n",
    "y_train = df_train.pa_approved.to_numpy()\n",
    "y_val = df_val.pa_approved.to_numpy()\n",
    "y_test = df_test.pa_approved.to_numpy()\n",
    "\n",
    "# each worker evaluate all models with all scores on a given set of features\n",
    "def worker(fid):\n",
    "    num_feats, cat_feats, _ = get_features(fid)\n",
    "    # utils.DataFrameFeatures extract columns of a dataframe to form input.\n",
    "    # It converts categorical columns into one hot encoding.\n",
    "    feat_map = utils.DataFrameFeatures(\n",
    "        num_cols=num_feats, cat_cols=cat_feats\n",
    "    ).fit(df_copy)\n",
    "    \n",
    "    X_train = feat_map.transform(df_train)\n",
    "    X_val = feat_map.transform(df_val)\n",
    "    X_test = feat_map.transform(df_test)\n",
    "    \n",
    "    f_data = []\n",
    "    for m_name, m in models:\n",
    "        # fit the model of training data\n",
    "        model = clone(m).fit(X_train, y_train)\n",
    "        \n",
    "        # evaluate the fitted model on various scoring functions\n",
    "        for s in score_funcs:\n",
    "            # on training data\n",
    "            item = evaluate_model(\n",
    "                fid, model, m_name,\n",
    "                X_train, y_train, 'train',\n",
    "                *s\n",
    "            )\n",
    "            f_data.append(item)\n",
    "            \n",
    "            # on validation data\n",
    "            item = evaluate_model(\n",
    "                fid, model, m_name,\n",
    "                X_val, y_val, 'validation',\n",
    "                *s\n",
    "            )\n",
    "            f_data.append(item)\n",
    "            \n",
    "            # on testing data\n",
    "            item = evaluate_model(\n",
    "                fid, model, m_name,\n",
    "                X_test, y_test, 'test',\n",
    "                *s\n",
    "            )\n",
    "            f_data.append(item)\n",
    "            \n",
    "    return f_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f18caa35-f74b-447a-b533-bbe36bbb1509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fid</th>\n",
       "      <th>model</th>\n",
       "      <th>data_type</th>\n",
       "      <th>score_func</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>train</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.734337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>train</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.734337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>train</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.846821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>train</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fid     model data_type score_func     score\n",
       "0    0  Baseline     train   accuracy  0.734337\n",
       "1    0  Baseline     train  precision  0.734337\n",
       "2    0  Baseline     train     recall  1.000000\n",
       "3    0  Baseline     train         f1  0.846821\n",
       "4    0  Baseline     train    roc_auc  0.500000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "# It takes couple of hours to evaluate all models, so it is a good idea to\n",
    "# save previously computed result. We provided our computed result in the\n",
    "# csv file named model_evals.csv in the data folder.\n",
    "_DEFAULT_EVAL_PATH = os.path.join(utils.DATA_FOLDER, 'model_evals.csv')\n",
    "def get_model_evaluation(path=_DEFAULT_EVAL_PATH):\n",
    "    if os.path.exists(path):\n",
    "        return pd.read_csv(path)\n",
    "    \n",
    "    map_data = []\n",
    "    # use multiple processes to accerlate the evaluation\n",
    "    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "        map_data = pool.map(worker, range(1, 64))\n",
    "    \n",
    "    data = []\n",
    "    for d in map_data:\n",
    "        data.extend(d)\n",
    "    \n",
    "    return save_evaluate_data(data, path)\n",
    "\n",
    "df_evals = get_model_evaluation()\n",
    "df_evals.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3590edf6-f6c6-4e51-93ab-8acf8e31b1ef",
   "metadata": {},
   "source": [
    "Results of the evaluations are stored in `df_evals`. We can decide what is the best feature set for a model under a particular scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3937593-3492-45f0-8b59-6b728e2e1530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data_type</th>\n",
       "      <th>score_func</th>\n",
       "      <th>score</th>\n",
       "      <th>fid</th>\n",
       "      <th>bin</th>\n",
       "      <th>drug</th>\n",
       "      <th>correct_diagnosis</th>\n",
       "      <th>tried_and_failed</th>\n",
       "      <th>contraindication</th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>test</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.769251</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>test</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.859208</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>test</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.778830</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>test</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>test</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model data_type score_func     score  fid  bin  drug  correct_diagnosis  \\\n",
       "0  AdaBoost      test   accuracy  0.769251   19    1     1                  0   \n",
       "1  AdaBoost      test         f1  0.859208   19    1     1                  0   \n",
       "2  AdaBoost      test  precision  0.778830   19    1     1                  0   \n",
       "3  AdaBoost      test     recall  1.000000    1    1     0                  0   \n",
       "4  AdaBoost      test     recall  1.000000    2    0     1                  0   \n",
       "\n",
       "   tried_and_failed  contraindication  random  \n",
       "0                 0                 1       0  \n",
       "1                 0                 1       0  \n",
       "2                 0                 1       0  \n",
       "3                 0                 0       0  \n",
       "4                 0                 0       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = (\n",
    "    df_evals\n",
    "    .groupby(['model', 'data_type', 'score_func'])\n",
    "    .agg({'score': 'max'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_temp = pd.merge(\n",
    "    df_temp, df_evals,\n",
    "    on=['model', 'data_type', 'score_func', 'score'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_best_evals = pd.merge(\n",
    "    df_temp, df_features, on='fid', how='left'\n",
    ")\n",
    "\n",
    "# get models we are intersted in for now\n",
    "df_best_evals = df_best_evals[\n",
    "    ~df_best_evals.model.isin(['Bayes'])\n",
    "]\n",
    "\n",
    "df_best_evals.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8160f4-3358-4f1e-a746-e0e3220c6c9b",
   "metadata": {},
   "source": [
    "The second row in the table means that for the **AdaBoost Classifier** evaluated on the test data using **f1 score**, the best feature subset is [`bin`, `drug`], which scores 0.859208. Can we say that the **AdaBoost Classifier** is a good model for our problem? To answer this question, we need to compare its f1 score to that of some baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8010b7a-f4ea-436c-be2f-db42389daa32",
   "metadata": {},
   "source": [
    "### The Baseline Model\n",
    "\n",
    "Recall from the [data exploration](./exploration.ipynb) that the target rate, or the overall PA approved rate, is 73.45%. We should look at the scores of the baseline model that always predicts 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3502f44e-1375-47c9-bac5-1a90309d6ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fid</th>\n",
       "      <th>model</th>\n",
       "      <th>data_type</th>\n",
       "      <th>score_func</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>train</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.734337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>train</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.734337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>train</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.846821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>train</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>test</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.734895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>test</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.734895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>test</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>test</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.847193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>test</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>validation</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.734374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>validation</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.734374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>validation</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>validation</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.846846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>validation</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fid     model   data_type score_func     score\n",
       "0     0  Baseline       train   accuracy  0.734337\n",
       "1     0  Baseline       train  precision  0.734337\n",
       "2     0  Baseline       train     recall  1.000000\n",
       "3     0  Baseline       train         f1  0.846821\n",
       "4     0  Baseline       train    roc_auc  0.500000\n",
       "5     0  Baseline        test   accuracy  0.734895\n",
       "6     0  Baseline        test  precision  0.734895\n",
       "7     0  Baseline        test     recall  1.000000\n",
       "8     0  Baseline        test         f1  0.847193\n",
       "9     0  Baseline        test    roc_auc  0.500000\n",
       "10    0  Baseline  validation   accuracy  0.734374\n",
       "11    0  Baseline  validation  precision  0.734374\n",
       "12    0  Baseline  validation     recall  1.000000\n",
       "13    0  Baseline  validation         f1  0.846846\n",
       "14    0  Baseline  validation    roc_auc  0.500000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline = df_evals[df_evals.model == 'Baseline']\n",
    "if df_baseline.shape[0] == 0:\n",
    "    data = []\n",
    "    for data_type, y_true in [('train', y_train), ('test', y_test), ('validation', y_val)]:\n",
    "        y_pred = np.ones_like(y_true)\n",
    "        for name, func in score_funcs:\n",
    "            s = func(y_true, y_pred)\n",
    "            data.append([0, 'Baseline', data_type, name, s])\n",
    "\n",
    "    df_baseline = save_evaluate_data(data)\n",
    "    df_evals = pd.concat([df_baseline, df_evals], axis=0)\n",
    "    df_evals.to_csv(_DEFAULT_EVAL_PATH, index=False)\n",
    "df_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344e7389-f126-4af8-b29b-143c8669791a",
   "metadata": {},
   "source": [
    "Take a look at the row with index 8 above, the f1 score for the Baseline model on the test set is 0.847193. Compared to 0.859208 for the AdaBoost classifier, we see that it is not convincing to conclude AdaBoost classifier is good.\n",
    "\n",
    "We notice that the roc auc scores for the baseline model on all data sets are 0.5, so it is essentially a random classifier. All other scores are relatively high, so it is better to use roc auc scores to select the best model. In the end of the notebook, we argue in details why accuracy is not a good measure of models in this classification problem.\n",
    "\n",
    "**Note: In binary classifications, roc auc score is the average of true positive rate and true negative rate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a557d0bb-829f-4351-9040-cb6920314fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data_type</th>\n",
       "      <th>score_func</th>\n",
       "      <th>score</th>\n",
       "      <th>fid</th>\n",
       "      <th>bin</th>\n",
       "      <th>drug</th>\n",
       "      <th>correct_diagnosis</th>\n",
       "      <th>tried_and_failed</th>\n",
       "      <th>contraindication</th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>validation</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.752150</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>validation</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.752150</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>Voting</td>\n",
       "      <td>validation</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.749010</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>validation</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.606872</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>validation</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.606872</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>validation</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.603134</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>SVC</td>\n",
       "      <td>validation</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.577263</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>SVC</td>\n",
       "      <td>validation</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.577263</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>validation</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model   data_type score_func     score  fid  bin  drug  \\\n",
       "414  Decision Tree  validation    roc_auc  0.752150   15    1     1   \n",
       "570  Random Forest  validation    roc_auc  0.752150   15    1     1   \n",
       "741         Voting  validation    roc_auc  0.749010   15    1     1   \n",
       "518       Logistic  validation    roc_auc  0.606872   23    1     1   \n",
       "519       Logistic  validation    roc_auc  0.606872   55    1     1   \n",
       "77        AdaBoost  validation    roc_auc  0.603134   19    1     1   \n",
       "686            SVC  validation    roc_auc  0.577263   29    1     0   \n",
       "687            SVC  validation    roc_auc  0.577263   61    1     0   \n",
       "92        Baseline  validation    roc_auc  0.500000    0    0     0   \n",
       "\n",
       "     correct_diagnosis  tried_and_failed  contraindication  random  \n",
       "414                  1                 1                 0       0  \n",
       "570                  1                 1                 0       0  \n",
       "741                  1                 1                 0       0  \n",
       "518                  1                 0                 1       0  \n",
       "519                  1                 0                 1       1  \n",
       "77                   0                 0                 1       0  \n",
       "686                  1                 1                 1       0  \n",
       "687                  1                 1                 1       1  \n",
       "92                   0                 0                 0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we look at the models with best roc auc scores at validation set\n",
    "fil = (df_best_evals.score_func == 'roc_auc') & (df_best_evals.data_type == 'validation')\n",
    "df_best_roc_auc = df_best_evals[fil].sort_values('score', ascending=False)\n",
    "\n",
    "df_best_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f63cd6-f472-4068-922f-177e22544646",
   "metadata": {},
   "source": [
    "The top 3 classifiers has close roc auc scores to 0.75, all modelled on the feature sets [`bin`, `drug`, `correct_diagnosis`, `tried_and_failed`]. They are aware that feature `random` is useless, which is good. However, it is surprising to see that they all decide that feature `contraindication` is not good for them when targeting at best roc auc scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a6f8dc-7d0f-4ab6-814f-46ef9690ae9b",
   "metadata": {},
   "source": [
    "We now put these all models with highest roc auc scores side by side with the baseline model so that we can compare them using all availabel scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "736ce461-a66d-4e58-839f-d240f65a02bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3871c_row0_col0, #T_3871c_row0_col4, #T_3871c_row1_col0, #T_3871c_row1_col4, #T_3871c_row2_col1, #T_3871c_row4_col3, #T_3871c_row6_col2 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3871c_row0_col1, #T_3871c_row1_col1, #T_3871c_row3_col3 {\n",
       "  background-color: #03476f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3871c_row0_col2, #T_3871c_row1_col2 {\n",
       "  background-color: #d9d8ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3871c_row0_col3, #T_3871c_row1_col3 {\n",
       "  background-color: #2987bc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3871c_row2_col0 {\n",
       "  background-color: #6ba5cd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3871c_row2_col2, #T_3871c_row2_col3, #T_3871c_row6_col0, #T_3871c_row6_col1, #T_3871c_row6_col4 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3871c_row2_col4 {\n",
       "  background-color: #023b5d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3871c_row3_col0 {\n",
       "  background-color: #2081b9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3871c_row3_col1, #T_3871c_row5_col4 {\n",
       "  background-color: #bdc8e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3871c_row3_col2 {\n",
       "  background-color: #0569a5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3871c_row3_col4 {\n",
       "  background-color: #93b5d6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3871c_row4_col0 {\n",
       "  background-color: #1278b4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3871c_row4_col1 {\n",
       "  background-color: #c1cae2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3871c_row4_col2 {\n",
       "  background-color: #04639b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3871c_row4_col4 {\n",
       "  background-color: #99b8d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3871c_row5_col0 {\n",
       "  background-color: #abbfdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3871c_row5_col1 {\n",
       "  background-color: #d8d7e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3871c_row5_col2 {\n",
       "  background-color: #056aa6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3871c_row5_col3 {\n",
       "  background-color: #197db7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3871c_row6_col3 {\n",
       "  background-color: #358fc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3871c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >score_func</th>\n",
       "      <th id=\"T_3871c_level0_col0\" class=\"col_heading level0 col0\" >accuracy</th>\n",
       "      <th id=\"T_3871c_level0_col1\" class=\"col_heading level0 col1\" >precision</th>\n",
       "      <th id=\"T_3871c_level0_col2\" class=\"col_heading level0 col2\" >recall</th>\n",
       "      <th id=\"T_3871c_level0_col3\" class=\"col_heading level0 col3\" >f1</th>\n",
       "      <th id=\"T_3871c_level0_col4\" class=\"col_heading level0 col4\" >roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3871c_level0_row0\" class=\"row_heading level0 row0\" >Decision Tree</th>\n",
       "      <td id=\"T_3871c_row0_col0\" class=\"data row0 col0\" >0.784086</td>\n",
       "      <td id=\"T_3871c_row0_col1\" class=\"data row0 col1\" >0.877707</td>\n",
       "      <td id=\"T_3871c_row0_col2\" class=\"data row0 col2\" >0.820280</td>\n",
       "      <td id=\"T_3871c_row0_col3\" class=\"data row0 col3\" >0.848023</td>\n",
       "      <td id=\"T_3871c_row0_col4\" class=\"data row0 col4\" >0.752150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3871c_level0_row1\" class=\"row_heading level0 row1\" >Random Forest</th>\n",
       "      <td id=\"T_3871c_row1_col0\" class=\"data row1 col0\" >0.784086</td>\n",
       "      <td id=\"T_3871c_row1_col1\" class=\"data row1 col1\" >0.877707</td>\n",
       "      <td id=\"T_3871c_row1_col2\" class=\"data row1 col2\" >0.820280</td>\n",
       "      <td id=\"T_3871c_row1_col3\" class=\"data row1 col3\" >0.848023</td>\n",
       "      <td id=\"T_3871c_row1_col4\" class=\"data row1 col4\" >0.752150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3871c_level0_row2\" class=\"row_heading level0 row2\" >Voting</th>\n",
       "      <td id=\"T_3871c_row2_col0\" class=\"data row2 col0\" >0.760073</td>\n",
       "      <td id=\"T_3871c_row2_col1\" class=\"data row2 col1\" >0.886092</td>\n",
       "      <td id=\"T_3871c_row2_col2\" class=\"data row2 col2\" >0.772610</td>\n",
       "      <td id=\"T_3871c_row2_col3\" class=\"data row2 col3\" >0.825469</td>\n",
       "      <td id=\"T_3871c_row2_col4\" class=\"data row2 col4\" >0.749010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3871c_level0_row3\" class=\"row_heading level0 row3\" >Logistic</th>\n",
       "      <td id=\"T_3871c_row3_col0\" class=\"data row3 col0\" >0.768302</td>\n",
       "      <td id=\"T_3871c_row3_col1\" class=\"data row3 col1\" >0.780987</td>\n",
       "      <td id=\"T_3871c_row3_col2\" class=\"data row3 col2\" >0.951258</td>\n",
       "      <td id=\"T_3871c_row3_col3\" class=\"data row3 col3\" >0.857754</td>\n",
       "      <td id=\"T_3871c_row3_col4\" class=\"data row3 col4\" >0.606872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3871c_level0_row4\" class=\"row_heading level0 row4\" >AdaBoost</th>\n",
       "      <td id=\"T_3871c_row4_col0\" class=\"data row4 col0\" >0.770033</td>\n",
       "      <td id=\"T_3871c_row4_col1\" class=\"data row4 col1\" >0.778863</td>\n",
       "      <td id=\"T_3871c_row4_col2\" class=\"data row4 col2\" >0.959188</td>\n",
       "      <td id=\"T_3871c_row4_col3\" class=\"data row4 col3\" >0.859671</td>\n",
       "      <td id=\"T_3871c_row4_col4\" class=\"data row4 col4\" >0.603134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3871c_level0_row5\" class=\"row_heading level0 row5\" >SVC</th>\n",
       "      <td id=\"T_3871c_row5_col0\" class=\"data row5 col0\" >0.752271</td>\n",
       "      <td id=\"T_3871c_row5_col1\" class=\"data row5 col1\" >0.767514</td>\n",
       "      <td id=\"T_3871c_row5_col2\" class=\"data row5 col2\" >0.950615</td>\n",
       "      <td id=\"T_3871c_row5_col3\" class=\"data row5 col3\" >0.849308</td>\n",
       "      <td id=\"T_3871c_row5_col4\" class=\"data row5 col4\" >0.577263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3871c_level0_row6\" class=\"row_heading level0 row6\" >Baseline</th>\n",
       "      <td id=\"T_3871c_row6_col0\" class=\"data row6 col0\" >0.734374</td>\n",
       "      <td id=\"T_3871c_row6_col1\" class=\"data row6 col1\" >0.734374</td>\n",
       "      <td id=\"T_3871c_row6_col2\" class=\"data row6 col2\" >1.000000</td>\n",
       "      <td id=\"T_3871c_row6_col3\" class=\"data row6 col3\" >0.846846</td>\n",
       "      <td id=\"T_3871c_row6_col4\" class=\"data row6 col4\" >0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2861deaedc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_helper(df):\n",
    "    ret = df.score.to_frame()\n",
    "    ret.index = df.score_func\n",
    "    ret = ret.transpose()\n",
    "    ret['model'] = df.model.iloc[0]\n",
    "    ret = ret.set_index('model')\n",
    "    return ret\n",
    "\n",
    "df_baseline_val_scores = transform_helper(df_baseline[df_baseline.data_type == 'validation'])\n",
    "dataframes = []\n",
    "\n",
    "# models with hightest roc auc scores\n",
    "for model in df_best_evals.model.unique():\n",
    "    fid = df_best_roc_auc[df_best_roc_auc.model == model].fid.iloc[0]\n",
    "    df_temp = df_evals[\n",
    "        (df_evals.model == model) & (df_evals.fid == fid) & (df_evals.data_type == 'validation')\n",
    "    ]\n",
    "    dataframes.append(transform_helper(df_temp))\n",
    "\n",
    "df_roc_auc_top = pd.concat(dataframes, axis=0).sort_values('roc_auc', ascending=False)\n",
    "df_roc_auc_top_styled = df_roc_auc_top.style.background_gradient(axis=0)\n",
    "dfi.export(df_roc_auc_top_styled, 'images/models_comparison_roc_auc.png')\n",
    "\n",
    "df_roc_auc_top_styled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3216230f-549e-4d70-b3a6-413040cd2b01",
   "metadata": {},
   "source": [
    "We highlighted the maximum score in each column. Decision tree and random forest performs similarly on this dataset. F1 score is the geometric average of precision and recall, and roc auc score is the average of true positive rate and true negative rate. They are both good measures in practice. **As it turns out, decision tree, random forest and voting classifier are still the top 3 models with respect to the f1 scores.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36860ad9-c3f6-481d-aaa8-ce0c298e7efa",
   "metadata": {},
   "source": [
    "We have a tie here for decision tree and random forest, no matter what scoring functions we look at. We can not confirmatively decide which one to use by just looking at the scores. Using feature importances as in [this notebook](./pa_classifier_feature_importances.ipynb), we can determine that random forest is better than decision tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5131aa45-a143-47d5-9eac-99ddab223ed2",
   "metadata": {},
   "source": [
    "## Fine Tuning\n",
    "\n",
    "In this section, we show two ways of fine tuning models. One way is to fine tune models' parameters using cross validation, and the other is to find tune models' feature sets. The second method is different from the previous models evaluation in the following way. For categorical features such as `bin`, we do one-hot encoding. `bin` has 4 categories, say, A, B, C, D. Then one-hot encoding gives us 3 new related binary features `bin_A`, `bin_B` and `bin_C`. Fine tuning the feature sets here means we might leave out some of the binary features from the same categorical features.\n",
    "\n",
    "One note is that, we will include back the `reject_code` feature, as leaving out some binary features from the same categorical features might lose information about the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6adc8-b9aa-4c3f-aa11-a1a790f652da",
   "metadata": {},
   "source": [
    "### Fine tuning the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05aff321-ce58-4695-a9f7-4a2b9f06ac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 available features:\n",
      "['correct_diagnosis', 'tried_and_failed', 'contraindication', 'bin_417380', 'bin_417614', 'bin_417740', 'drug_A', 'drug_B', 'reject_code_70', 'reject_code_75']\n"
     ]
    }
   ],
   "source": [
    "feat_map = utils.DataFrameFeatures(\n",
    "    num_cols=['correct_diagnosis', 'tried_and_failed', 'contraindication'],\n",
    "    cat_cols = ['bin', 'drug', 'reject_code']\n",
    ")\n",
    "feat_map.fit(df_pa)\n",
    "feature_set = feat_map.feature_names_\n",
    "n_feat = len(feature_set)\n",
    "\n",
    "print(f'{n_feat} available features:\\n{feature_set}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea4d88-a27c-4cf0-a984-08a65267c94f",
   "metadata": {},
   "source": [
    "### Fine tuning parameters\n",
    "\n",
    "We are going to fine tune models' parameters. We focus on the random forest model we found in the Model Evaluation section with the best roc auc score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dec0fc3-aa9d-4824-af08-06149b0ae169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data_type</th>\n",
       "      <th>score_func</th>\n",
       "      <th>score</th>\n",
       "      <th>fid</th>\n",
       "      <th>bin</th>\n",
       "      <th>drug</th>\n",
       "      <th>correct_diagnosis</th>\n",
       "      <th>tried_and_failed</th>\n",
       "      <th>contraindication</th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>validation</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.75215</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>validation</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.75215</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model   data_type score_func    score  fid  bin  drug  \\\n",
       "414  Decision Tree  validation    roc_auc  0.75215   15    1     1   \n",
       "570  Random Forest  validation    roc_auc  0.75215   15    1     1   \n",
       "\n",
       "     correct_diagnosis  tried_and_failed  contraindication  random  \n",
       "414                  1                 1                 0       0  \n",
       "570                  1                 1                 0       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remind ourselves the best random forest model\n",
    "fil = (df_best_evals.score_func == 'roc_auc') & (df_best_evals.data_type == 'validation')\n",
    "fil = fil & (df_best_evals.model.isin(['Random Forest', 'Decision Tree']))\n",
    "df_best_evals[fil]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af09d90-fcd4-4784-8a3f-61af94864c46",
   "metadata": {},
   "source": [
    "The best feature set for decision tree and random forest is [`bin`, `drug`, `correct_diagnosis`, `tried_and_failed`] with the best roc auc score being 0.75215. We are going to tune parameters for random forest to improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aac05d6b-73d0-4047-96f4-d2568eef149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up training set for `fine_tune_feature_set`\n",
    "feat_map = utils.DataFrameFeatures(\n",
    "    num_cols=['correct_diagnosis', 'tried_and_failed'],\n",
    "    cat_cols = ['bin', 'drug']\n",
    ")\n",
    "feat_map.fit(df_pa)\n",
    "\n",
    "X_ft_train = feat_map.transform(df_train)\n",
    "y_ft_train = df_train.pa_approved.to_numpy()\n",
    "X_ft_test = feat_map.transform(df_test)\n",
    "y_ft_test = df_test.pa_approved.to_numpy()\n",
    "X_ft_val = feat_map.transform(df_val)\n",
    "y_ft_val = df_val.pa_approved.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd72bb-e25b-4299-9528-099fca6a9d22",
   "metadata": {},
   "source": [
    "Doing a grid search of parameters for random forest takes a long time. Our strategy is to fine tune parameters for decision tree first, then use these tuned parameters for random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61ff4f86-eca2-4986-80ab-9b55a04a3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0903ba62-fd41-4938-b5ff-33131d1774aa",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb22201d-9c63-4194-952d-77937e84d30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for decision tree:\n",
      "{'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "dtc_search = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    param_grid={\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': range(5, 16),\n",
    "        'min_samples_split': range(2, 7)\n",
    "    },\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    ").fit(X_ft_train, y_ft_train)\n",
    "\n",
    "print('The best parameters for decision tree:')\n",
    "print(dtc_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15834bc9-a102-4cd4-981e-c5e0d18a0679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score for tuned decision tree: 0.75215\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(**dtc_search.best_params_).fit(X_ft_train, y_ft_train)\n",
    "y_pred = dtc.predict(X_ft_val)\n",
    "dtc_roc = roc_auc_score(y_ft_val, y_pred)\n",
    "print(f'roc auc score for tuned decision tree: {dtc_roc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d10a5b-2d0e-49bd-b93d-0846b523d9ad",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "213e343b-32a8-459c-beb2-459533175f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for random forest:\n",
      "{'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 2, 'n_estimators': 15}\n"
     ]
    }
   ],
   "source": [
    "rfc_search = GridSearchCV(\n",
    "    RandomForestClassifier(**dtc_search.best_params_, random_state=614),\n",
    "    param_grid={\n",
    "        'n_estimators': range(11, 21)\n",
    "    },\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    ").fit(X_ft_train, y_ft_train)\n",
    "\n",
    "print('The best parameters for random forest:')\n",
    "print(dtc_search.best_params_ | rfc_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e78fd515-1178-4528-a5e8-773f31eb51ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score for tuned random forest: 0.75215\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    **dtc_search.best_params_, **rfc_search.best_params_, random_state=614\n",
    ").fit(X_ft_train, y_ft_train)\n",
    "\n",
    "y_pred = rfc.predict(X_ft_val)\n",
    "dtc_roc = roc_auc_score(y_ft_val, y_pred)\n",
    "print(f'roc auc score for tuned random forest: {dtc_roc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bb420c-2ac7-4151-b305-38a06442fa6d",
   "metadata": {},
   "source": [
    "Unfortunately, we don't see improvement roc auc score. We guess the reason to be that the default parameters are already the best for the random forest model in this particular classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d40df34-58e5-4bc4-82ec-9939f5d4641e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>score_func</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.816215</td>\n",
       "      <td>0.836762</td>\n",
       "      <td>0.931449</td>\n",
       "      <td>0.881571</td>\n",
       "      <td>0.714540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.816215</td>\n",
       "      <td>0.836762</td>\n",
       "      <td>0.931449</td>\n",
       "      <td>0.881571</td>\n",
       "      <td>0.714540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayes</th>\n",
       "      <td>0.816215</td>\n",
       "      <td>0.836762</td>\n",
       "      <td>0.931449</td>\n",
       "      <td>0.881571</td>\n",
       "      <td>0.714540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting</th>\n",
       "      <td>0.797509</td>\n",
       "      <td>0.838698</td>\n",
       "      <td>0.896730</td>\n",
       "      <td>0.866744</td>\n",
       "      <td>0.709961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.750022</td>\n",
       "      <td>0.765949</td>\n",
       "      <td>0.949850</td>\n",
       "      <td>0.848044</td>\n",
       "      <td>0.573706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.749550</td>\n",
       "      <td>0.765959</td>\n",
       "      <td>0.948901</td>\n",
       "      <td>0.847672</td>\n",
       "      <td>0.573655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.734374</td>\n",
       "      <td>0.734374</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846846</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.729674</td>\n",
       "      <td>0.763474</td>\n",
       "      <td>0.915529</td>\n",
       "      <td>0.832616</td>\n",
       "      <td>0.565687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "score_func     accuracy  precision    recall        f1   roc_auc\n",
       "model                                                           \n",
       "Decision Tree  0.816215   0.836762  0.931449  0.881571  0.714540\n",
       "Random Forest  0.816215   0.836762  0.931449  0.881571  0.714540\n",
       "Bayes          0.816215   0.836762  0.931449  0.881571  0.714540\n",
       "Voting         0.797509   0.838698  0.896730  0.866744  0.709961\n",
       "SVC            0.750022   0.765949  0.949850  0.848044  0.573706\n",
       "Logistic       0.749550   0.765959  0.948901  0.847672  0.573655\n",
       "Baseline       0.734374   0.734374  1.000000  0.846846  0.500000\n",
       "AdaBoost       0.729674   0.763474  0.915529  0.832616  0.565687"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = []\n",
    "for model in df_evals.model.unique():\n",
    "    fid = 31 if model != 'Baseline' else 0\n",
    "    df_temp = df_evals[\n",
    "        (df_evals.data_type == 'validation') & (df_evals.model == model) \\\n",
    "        & (df_evals.fid == fid)\n",
    "    ]\n",
    "    dataframes.append(transform_helper(df_temp))\n",
    "\n",
    "df_best_acc = pd.concat(dataframes, axis=0)\n",
    "df_best_acc.sort_values('accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131e3e0f-8dff-4390-9b54-bfdc764c0fdb",
   "metadata": {},
   "source": [
    "The Bayes optimal predictor is indeed the best in accuracy. Decision tree and random forest can do as good as the Bayes optimal predictor. It shows that if we care only about accuracy, the Bayes optimal predictor should be the choice. The accuracy score is not a good measure of models in this classification problem, as it limits us to the Bayes optimal predictor, and lose flexibility in other scores as the Bayes optimal predictor has no parameters to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240f4a28-8c15-4370-ab6a-35616b9c0597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
