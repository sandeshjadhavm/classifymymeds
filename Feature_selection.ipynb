{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e6cfe9d-dbf5-4736-8446-496651bb8f8b",
   "metadata": {},
   "source": [
    "# Feature Selection \n",
    "This file performs feature selection for SVC, logistic regression, AdaBoost, and the Bayes Classifier to PA classification. The feature selection is done by first creating a power set using all possible features, then training the models on the combinations of features and then storing the scores. This notebook is a helper notebook for CMM-model-assessment.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fcccd3-4d9c-4193-b31c-bd69a2905f0f",
   "metadata": {},
   "source": [
    "## Load and Clean Data\n",
    "First we import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874373ef-95bb-45d7-b8f9-c34a4e8c7887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a815f359-3ca4-484f-9058-013c60657d45",
   "metadata": {},
   "source": [
    "Next, we load and clean the data. Then we merge the 3 dataframes into one and then split the resulting dataframe into two. \n",
    "In the first group, we have the data corresponding to pharmacy fills in which a PA was not requested and in the second we have the data corresponding to prescriptions for which a PA was requested.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4730dd-8756-4538-b646-1c5b69545d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_date=pd.read_csv(\"data/dim_date.csv\")\n",
    "df_claim=pd.read_csv(\"data/dim_claims.csv\")\n",
    "df_pa=pd.read_csv(\"data/dim_pa.csv\")\n",
    "df_bridge=pd.read_csv(\"data/bridge.csv\")\n",
    "\n",
    "# Clean data so all reject_code values are integers\n",
    "df_claim['reject_code'] = df_claim.reject_code.fillna(0).astype(int)\n",
    "\n",
    "# Merge the data frames\n",
    "df_main = pd.merge(df_claim, df_bridge, on='dim_claim_id')\n",
    "df_main = pd.merge(df_main, df_pa, how='left', on='dim_pa_id')\n",
    "df_main = pd.merge(df_main, df_date, how='left', on='dim_date_id')\n",
    "\n",
    "# split the data frames into two -- PA requested or not\n",
    "df_main_wPA = df_main[~np.isnan(df_main.pa_approved)].copy()\n",
    "df_main_noPA = df_main[np.isnan(df_main.pa_approved)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8680a-89c7-4cc5-9d24-a05491d8d215",
   "metadata": {},
   "source": [
    "Here is the dataframe corresponding to pharmacy fills with no PA requested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d99f19-51d0-4482-bd1f-92f62dce4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_noPA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0307b2a-6877-4ad1-b228-bcaa52438bda",
   "metadata": {},
   "source": [
    "Here is the data frame corresponding to pharmacy fills with a PA requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a6d47a-0b44-49a5-b943-d62e7fb1a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_wPA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ef1c4b-8bdc-4866-8f52-bdbc046093f7",
   "metadata": {},
   "source": [
    "Now we use one-hot encoding to turn the categorical features into binary features. There are two categorical features; the bin i.e. the payer and the drug type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc2868b-2ca2-440a-a756-cd2c9870b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode all categorical features in the case that a PA was requested \n",
    "df_aug=df_main_wPA.copy()\n",
    "df_aug['70'] = pd.get_dummies(df_aug['reject_code'])[70]\n",
    "df_aug['75'] = pd.get_dummies(df_aug['reject_code'])[75]\n",
    "df_aug['76'] = pd.get_dummies(df_aug['reject_code'])[76]\n",
    "df_aug['bin417380']=pd.get_dummies(df_aug['bin'])[417380]\n",
    "df_aug['bin999001']=pd.get_dummies(df_aug['bin'])[999001]\n",
    "df_aug['bin417740']=pd.get_dummies(df_aug['bin'])[417740]\n",
    "df_aug['bin417614']=pd.get_dummies(df_aug['bin'])[417614]\n",
    "df_aug['drug_A']=pd.get_dummies(df_aug['drug'])['A']\n",
    "df_aug['drug_B']=pd.get_dummies(df_aug['drug'])['B']\n",
    "df_aug['drug_C']=pd.get_dummies(df_aug['drug'])['C']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6217ac50-63ee-450b-8839-0c159d33ceed",
   "metadata": {},
   "source": [
    "Now we make the train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdab55f9-a625-4c37-9e49-1e5c942854e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# keep all except temporal features for now \n",
    "X=df_aug[['70', '75', '76', 'bin417380', 'bin999001','bin417740', 'bin417614','correct_diagnosis', 'contraindication', 'tried_and_failed', 'drug_A', 'drug_B','drug_C']]\n",
    "y=df_aug[['pa_approved']]\n",
    "X_train_gen,X_test_gen,y_train_gen,y_test_gen = train_test_split(X,y,\n",
    "                                                test_size=.2,\n",
    "                                                shuffle=True,\n",
    "                                                stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce292540-090f-4b4e-995d-d987df209bb8",
   "metadata": {},
   "source": [
    "## Models of Interest\n",
    "We will analyze the following classifiers: \n",
    "1. logistic regression;\n",
    "2. Bayes classifier;\n",
    "3. random forests;\n",
    "4. linear support vector machine; \n",
    "5. AdaBoost. \n",
    "\n",
    "We first import the models and load the class for the Bayes/Group Average classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ce3e1d-4211-4305-80c5-ab826944c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10463653-8bd8-49e8-8d3f-153a67a4835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "\n",
    "class GroupAverageClassifier(BaseEstimator, TransformerMixin, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.approved_count_ = Counter()\n",
    "        self.total_count_ = Counter()\n",
    "        for r, t in zip(X, y):\n",
    "            g = tuple(r)\n",
    "            self.approved_count_[g] += t\n",
    "            self.total_count_[g] += 1\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.predict_proba(X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        prob = self.predict_prob(X)\n",
    "        pred = (prob > 0.5).astype(int)\n",
    "        return pred\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        prob = np.zeros(X.shape[0])\n",
    "        eps = 1e-4\n",
    "        for i, r in enumerate(X):\n",
    "            g = tuple(r)\n",
    "            prob[i] = self.approved_count_[g] / (self.total_count_[g] + eps)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060e6542-8093-42ff-a92d-7c74fd7531fa",
   "metadata": {},
   "source": [
    "## Metrics of Interest \n",
    "We will be interested in accuracy, recall, precision, f1 and the area under the roc curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db3933d-00db-470c-86ab-e555a56c321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4114e9e-b981-4d44-b5fa-d44254e6bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_func_name(f):\n",
    "    name = f.__name__\n",
    "    if name.endswith('_score'):\n",
    "        name = name[:-6]\n",
    "    return name\n",
    "\n",
    "default_scores = [accuracy_score, precision_score, recall_score,f1_score, roc_auc_score, balanced_accuracy_score]\n",
    "default_names = [get_func_name(f) for f in default_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e69587-87db-46f8-b3c1-433fd6c1dbfc",
   "metadata": {},
   "source": [
    "We now write the functions that build the powerset from all of the features and evaluate the models on this collection of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe67f3fb-c751-4abe-a5af-971cd8586bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset_no_empty(s):\n",
    "    power_set = []\n",
    "    x = len(s)\n",
    "    for i in range(1 << x):\n",
    "        power_set.append([s[j] for j in range(x) if (i & (1 << j))])\n",
    "            \n",
    "    return power_set[1:]\n",
    "\n",
    "def get_all_scores(model):    \n",
    "    cutoff = .5\n",
    "    acc = np.empty(len(possible_features))\n",
    "    precision = np.empty(len(possible_features))\n",
    "    recall = np.empty(len(possible_features))\n",
    "    f1 = np.empty(len(possible_features))\n",
    "    roc = np.empty(len(possible_features))\n",
    "    acc_t = np.empty(len(possible_features))\n",
    "    precision_t = np.empty(len(possible_features))\n",
    "    recall_t = np.empty(len(possible_features))\n",
    "    f1_t = np.empty(len(possible_features))\n",
    "    roc_t=np.empty(len(possible_features))\n",
    "\n",
    "    df=pd.DataFrame(columns=['acc', 'prec', 'recall', 'f1', 'roc', 'acc_t','prec_t', 'recall_t', 'f1_t', 'roc_t' ])\n",
    "\n",
    "    for j in range(len(possible_features)):\n",
    "        ## get X and y\n",
    "        print(j)\n",
    "        X_mini = np.array(X_train_gen[possible_features[j]])\n",
    "\n",
    "        y_train=np.array(y_train_gen).ravel()\n",
    "\n",
    "        # Cloning the regression makes a fresh regression \n",
    "        # model for each run\n",
    "        clone_reg = clone(model)\n",
    "\n",
    "        # fit the model\n",
    "        clone_reg.fit(X_mini, y_train)\n",
    "        ## assign the value based on the cutoff\n",
    "        y_train_pred = clone_reg.predict(X_mini)\n",
    "\n",
    "        X_mini_t = np.array(X_test_gen[possible_features[j]])\n",
    "        y_test=np.array(y_test_gen).ravel()\n",
    "        \n",
    "        y_test_pred = clone_reg.predict(X_mini_t)\n",
    "\n",
    "\n",
    "        acc[j] = accuracy_score(y_train_pred,y_train)\n",
    "        precision[j] = precision_score(y_train,y_train_pred)\n",
    "        recall[j] = recall_score(y_train,y_train_pred)\n",
    "        f1[j] = f1_score(y_train,y_train_pred)\n",
    "        roc[j]=roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "        acc_t[j] = accuracy_score(y_test_pred,y_test)\n",
    "        precision_t[j] = precision_score(y_test,y_test_pred)\n",
    "        recall_t[j] = recall_score(y_test,y_test_pred)\n",
    "        f1_t[j] = f1_score(y_test,y_test_pred)\n",
    "        roc_t[j]=roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "    df['acc']=acc\n",
    "    df['acc_t']=acc_t\n",
    "    df['prec']=precision\n",
    "    df['prec_t']=precision_t\n",
    "    df['recall']=recall\n",
    "    df['recall_t']=recall_t\n",
    "    df['f1']=f1\n",
    "    df['f1_t']=f1_t\n",
    "    df['roc']=roc\n",
    "    df['roc']=roc_t\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8769aa-76e6-46c4-ac2c-a4b43ce128c6",
   "metadata": {},
   "source": [
    "The features we are interested in are given below. Recall that when we encode a categorical feature with $K$ classes via one-hot encoding, we only keet $K-1$ of the resulting binary features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b1159-f4d6-497c-95f0-9a4fef4160fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_features=powerset_no_empty(['70', '75', 'bin417380','bin417740', 'bin417614','correct_diagnosis', 'contraindication', 'tried_and_failed', 'drug_A', 'drug_B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ad8e55-97c0-4388-8b9d-d2fc0dd11918",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45eff1b-eb14-4a11-9990-b213d09b7afe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_reg=LogisticRegression()\n",
    "df= get_all_scores(log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afbad1f-86ee-49e6-a7cb-f40497774250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='roc', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afabc9b9-5524-496f-b5f9-2f7cb8c35fa4",
   "metadata": {},
   "source": [
    "Our goal is to extract the features with the best roc score. However, the baseline model (see pa_classifier.ipynb) has an accuracy of .73, so we reject the first two feature combinations here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12107450-ff60-421b-96c5-b73b67b28ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We will use features: ', possible_features[656], 'for logistic regression.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e32446-2133-42cf-b368-c2ad40869c0e",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082886bd-2538-46e9-ab56-c680031b5218",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "SVC = LinearSVC(C=1)\n",
    "df_SVC=get_all_scores(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c1c75-6673-487b-aa77-5f598e519ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SVC.sort_values(by='roc', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f525098e-92ee-44fb-ae06-9e156df63975",
   "metadata": {},
   "source": [
    "Again, we reject the first two feature combinations because the accuracy is too low and we choose the next combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e3195-f30d-4d2a-9f92-47a4513ff20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We will use features: ',possible_features[658],'for the linear support vector machine.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99efe818-2582-4ea6-9ab3-d952bce6c5d4",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5189710f-d234-4ad3-9aa3-d0e2fb9ec434",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "            n_estimators = 10,\n",
    "            algorithm=\"SAMME.R\",\n",
    "            learning_rate = 0.5\n",
    "        )\n",
    "df_ada=get_all_scores(ada_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f5c81f-707e-4fbc-a1f7-e98c46d92d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ada.sort_values(by='roc', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1614951-0c22-401c-b4c6-84cad3771de0",
   "metadata": {},
   "source": [
    "This time, we reject the first three feature combinations for hacing accuracy scores that are too low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714852c5-95bd-43db-9ddb-36ddcfdc6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We will use features:',possible_features[838],'for AdaBoost.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3abe5c-05be-4d59-a371-8fb41c991c51",
   "metadata": {},
   "source": [
    "### Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac8205-c587-4098-964f-db3b1a896a62",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "bayes_clf=GroupAverageClassifier()\n",
    "df_bayes=get_all_scores(bayes_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8e9d6-56dd-4540-bfd8-245d595766ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bayes.sort_values(by='roc', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b115d5d6-897c-48c9-b579-00542eb80e3b",
   "metadata": {},
   "source": [
    "We reject the first two feature combinations and choose the third. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a1c593-b5dc-4934-98ab-5007447b6294",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We will use features: ', possible_features[669],'for the Bayes Classifier.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2580265b-6a88-44de-aed3-393fb480ac65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
